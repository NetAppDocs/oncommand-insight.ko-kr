---
sidebar: sidebar 
permalink: task_config_telegraf_hadoop.html 
keywords: telegraf, installation, install, Hadoop 
summary: Hadoop 데이터 수집기 구성 
---
= Hadoop Data Collector
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Cloud Insights는 이 데이터 수집기를 사용하여 Hadoop에서 메트릭을 수집합니다.



== 설치

. 관측성 > 수집기 * 에서 * + Data Collector * 를 클릭합니다. Hadoop 선택
+
Telegraf 에이전트가 설치된 운영 체제 또는 플랫폼을 선택합니다.

. 수집용 에이전트를 아직 설치하지 않았거나 다른 운영 체제 또는 플랫폼용 에이전트를 설치하려는 경우, _지침 표시_를 클릭하여 를 확장합니다 link:task_config_telegraf_agent.html["에이전트 설치"] 지침.
. 이 데이터 수집기에 사용할 Agent Access 키를 선택합니다. Agent 액세스 키 * 버튼을 클릭하여 새 Agent 액세스 키를 추가할 수 있습니다. 모범 사례: OS/플랫폼별로 데이터 수집기를 그룹화하려는 경우에만 다른 에이전트 액세스 키를 사용하십시오.
. 구성 단계에 따라 데이터 수집기를 구성합니다. 지침은 데이터 수집에 사용하는 운영 체제 또는 플랫폼의 유형에 따라 다릅니다.


image:HadoopDCConfigLinux-1.png["Hadoop 구성"]
image:HadoopDCConfigLinux-2.png["Hadoop 구성"]



== 설정

전체 Hadoop 구축에는 다음 구성 요소가 포함됩니다.

* NameNode: HDFS(Hadoop Distributed File System) 운영 시스템입니다. 일련의 DataNode를 조정합니다.
* Secondary NameNode: main NameNode에 대한 웜 페일오버입니다. Hadoop에서는 NameNode에 대한 프로모션이 자동으로 수행되지 않습니다. Secondary NameNode는 NameNode에서 정보를 수집하여 필요할 때 상향 이동할 수 있도록 준비합니다.
* DataNode: 데이터의 실제 소유자입니다.
* ResourceManager: 컴퓨팅 운영 시스템(YARN)입니다. 일련의 NodeManager를 조정합니다.
* NodeManager: 컴퓨팅 리소스로, 응용 프로그램 실행을 위한 실제 위치입니다.
* JobHistoryServer: 모든 작업 내역 관련 요청을 처리합니다.


Hadoop 플러그인은 Telegraf의 Jolokia 플러그인을 기반으로 합니다. 모든 Hadoop 구성 요소에서 정보를 수집하는 요구 사항과 같이 JMX는 모든 구성 요소에서 Jolokia를 통해 구성 및 노출되어야 합니다.



=== 호환성

Hadoop 버전 2.9.2를 기준으로 구성이 개발되었습니다.



=== 설정 중입니다



==== 졸로키아 에이전트 용기

모든 개별 구성 요소의 경우 Jolokia 에이전트 JAR 파일 버전을 다운로드해야 합니다. 에 대해 테스트한 버전은 입니다 link:https://jolokia.org/download.html["졸로키아 에이전트 1.6.0"].

아래 지침에서는 다운로드한 jar 파일(jolokia-jvm-1.6.0-agent.jar)이 '/opt/hADOOP/lib/' 위치에 있다고 가정합니다.



==== NameNode입니다

Jolokia API를 노출하도록 NameNode를 구성하려면 <Hadoop_HOME>/etc/Hadoop/Hadoop-env.sh에서 다음을 설정할 수 있습니다.

[listing]
----
export HADOOP_NAMENODE_OPTS="$HADOOP_NAMENODE_OPTS -javaagent:/opt/hadoop/lib/jolokia-jvm-1.6.0-agent.jar=port=7800,host=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8000 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password"
You can choose a different port for JMX (8000 above) and Jolokia (7800). If you have an internal IP to lock Jolokia onto you can replace the "catch all" 0.0.0.0 by your own IP. Notice this IP needs to be accessible from the telegraf plugin. You can use the option '-Dcom.sun.management.jmxremote.authenticate=false' if you don't want to authenticate. Use at your own risk.
----


==== Secondary NameNode입니다

보조 NameNode를 구성하여 Jolokia API를 표시하려면 <Hadoop_HOME>/etc/Hadoop/Hadoop-env.sh에서 다음을 설정할 수 있습니다.

[listing]
----
export HADOOP_SECONDARYNAMENODE_OPTS="$HADOOP_SECONDARYNAMENODE_OPTS -javaagent:/opt/hadoop/lib/jolokia-jvm-1.6.0-agent.jar=port=7802,host=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8002 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password"
You can choose a different port for JMX (8002 above) and Jolokia (7802). If you have an internal IP to lock Jolokia onto you can replace the "catch all" 0.0.0.0 by your own IP. Notice this IP needs to be accessible from the telegraf plugin. You can use the option '-Dcom.sun.management.jmxremote.authenticate=false' if you don't want to authenticate. Use at your own risk.
----


==== DataNode 를 선택합니다

Jolokia API를 노출하도록 DataNodes를 구성하려면 <Hadoop_HOME>/etc/Hadoop/Hadoop-env.sh에서 다음을 설정할 수 있습니다.

[listing]
----
export HADOOP_DATANODE_OPTS="$HADOOP_DATANODE_OPTS -javaagent:/opt/hadoop/lib/jolokia-jvm-1.6.0-agent.jar=port=7801,host=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8001 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password"
You can choose a different port for JMX (8001 above) and Jolokia (7801). If you have an internal IP to lock Jolokia onto you can replace the "catch all" 0.0.0.0 by your own IP. Notice this IP needs to be accessible from the telegraf plugin. You can use the option '-Dcom.sun.management.jmxremote.authenticate=false' if you don't want to authenticate. Use at your own risk.
----


==== ResourceManager 를 클릭합니다

ResourceManager를 구성하여 Jolokia API를 노출하려면 <Hadoop_HOME>/etc/Hadoop/Hadoop-env.sh에서 다음을 설정할 수 있습니다.

[listing]
----
export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS -javaagent:/opt/hadoop/lib/jolokia-jvm-1.6.0-agent.jar=port=7803,host=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8003 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password"
You can choose a different port for JMX (8003 above) and Jolokia (7803). If you have an internal IP to lock Jolokia onto you can replace the "catch all" 0.0.0.0 by your own IP. Notice this IP needs to be accessible from the telegraf plugin. You can use the option '-Dcom.sun.management.jmxremote.authenticate=false' if you don't want to authenticate. Use at your own risk.
----


==== NodeManager를 참조하십시오

NodeManagers가 Jolokia API를 노출하도록 구성하려면 <Hadoop_HOME>/etc/Hadoop/Hadoop-env.sh에서 다음을 설정할 수 있습니다.

[listing]
----
export YARN_NODEMANAGER_OPTS="$YARN_NODEMANAGER_OPTS -javaagent:/opt/hadoop/lib/jolokia-jvm-1.6.0-agent.jar=port=7804,host=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8004 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password"
You can choose a different port for JMX (8004 above) and Jolokia (7804). If you have an internal IP to lock Jolokia onto you can replace the "catch all" 0.0.0.0 by your own IP. Notice this IP needs to be accessible from the telegraf plugin. You can use the option '-Dcom.sun.management.jmxremote.authenticate=false' if you don't want to authenticate. Use at your own risk.
----


==== JobHistoryServer를 참조하십시오

JobHistoryServer가 Jolokia API를 표시하도록 구성하려면 <Hadoop_Home>/etc/Hadoop/Hadoop-env.sh에서 다음을 설정할 수 있습니다.

[listing]
----
export HADOOP_JOB_HISTORYSERVER_OPTS="$HADOOP_JOB_HISTORYSERVER_OPTS -javaagent:/opt/hadoop/lib/jolokia-jvm-1.6.0-agent.jar=port=7805,host=0.0.0.0 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8005 -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password"
You can choose a different port for JMX (8005 above) and Jolokia (7805). If you have an internal IP to lock Jolokia onto you can replace the "catch all" 0.0.0.0 by your own IP. Notice this IP needs to be accessible from the telegraf plugin. You can use the option '-Dcom.sun.management.jmxremote.authenticate=false' if you don't want to authenticate. Use at your own risk.
----


== 개체 및 카운터

다음 개체와 해당 카운터가 수집됩니다.

[cols="<.<,<.<,<.<,<.<"]
|===
| 오브젝트: | 식별자: | 특성: | 데이터 요소: 


| Hadoop 보조 NameNode | 클러스터
네임스페이스
서버 | 노드 이름
노드 IP
컴파일 정보
버전 | GC 카운트
GC 사본 수
GC 마크 스위프 컴팩트 카운트
GC 번호 정보 임계값을 초과했습니다
GC 번호 경고 임계값을 초과했습니다
GC 시간
GC 복사 시간
GC Marks Sweep Compact Time
GC 총 추가 수면 시간
로그 오류 수
로그 치명적 개수
로그 정보 개수
로그 경고 수
메모리 힙 커밋됨
메모리 힙 최대
메모리 힙 사용
최대 메모리
메모리가 비힙 커밋되었습니다
메모리 비힙 최대
메모리 비힙 사용
스레드가 차단되었습니다
새 스레드
스레드 실행 가능
스레드가 종료되었습니다
스레드 시간 대기 중
스레드가 대기 중입니다 


| Hadoop NodeManager를 참조하십시오 | 클러스터
네임스페이스
서버 | 노드 이름
노드 IP | 컨테이너가 할당되었습니다
메모리 할당
메모리가 할당되었습니다
가상 코어 할당 Oportunistic
할당된 가상 코어
사용 가능한 메모리
사용 가능한 가상 코어
디렉터리가 로컬에 맞지 않습니다
디렉터리 불량 로그
정리 전 캐시 크기
컨테이너 시작 지속 시간 평균 시간
컨테이너 시작 기간 작업 수입니다
컨테이너가 완료되었습니다
컨테이너가 실패했습니다
컨테이너 초기화
컨테이너가 중지되었습니다
컨테이너가 시작되었습니다
컨테이너 재초기화
장애 시 컨테이너가 롤백되었습니다
컨테이너가 실행 중입니다
디스크 사용률 양호한 로컬 디렉토리
디스크 활용률 양호한 로그 디렉토리
비공개로 삭제된 바이트
바이트 공개 삭제됨
컨테이너 실행 기회
삭제된 총 바이트 수
연결 임의 재생
셔플 출력 바이트
무작위 출력 실패
무작위 출력 정상
GC 카운트
GC 사본 수
GC 마크 스위프 컴팩트 카운트
GC 번호 정보 임계값을 초과했습니다
GC 번호 경고 임계값을 초과했습니다
GC 시간
GC 복사 시간
GC Marks Sweep Compact Time
GC 총 추가 수면 시간
로그 오류 수
로그 치명적 개수
로그 정보 개수
로그 경고 수
메모리 힙 커밋됨
메모리 힙 최대
메모리 힙 사용
최대 메모리
메모리가 비힙 커밋되었습니다
메모리 비힙 최대
메모리 비힙 사용
스레드가 차단되었습니다
새 스레드
스레드 실행 가능
스레드가 종료되었습니다
스레드 시간 대기 중
스레드가 대기 중입니다 


| Hadoop ResourceManager를 참조하십시오 | 클러스터
네임스페이스
서버 | 노드 이름
노드 IP | ApplicationMaster 시작 지연 평균
ApplicationMaster 시작 지연 번호
ApplicationMaster 등록 지연 평균
ApplicationMaster 등록 지연 번호
NodeManager 활성 번호입니다
NodeManager에서 제외된 번호입니다
NodeManager 디누락된 번호
NodeManager 번호가 손실되었습니다
NodeManager 재부팅 번호
NodeManager 종료 번호입니다
NodeManager 정상 번호입니다
NodeManager 메모리 제한
NodeManager 가상 코어 수 제한
사용된 용량
활성 애플리케이션
활성 사용자
할당된 애그리게이트 컨테이너
애그리게이트 컨테이너가 비어 있습니다
애그리게이트 컨테이너가 릴리스되었습니다
집계 메모리 초 사전 비움
애그리게이트 노드 로컬 컨테이너가 할당되었습니다
애그리게이트 오프 스위치 컨테이너가 할당되었습니다
애그리게이트 Ack 로컬 컨테이너가 할당되었습니다
애그리게이트 가상 코어 수 초 전
컨테이너가 할당되었습니다
메모리가 할당되었습니다
할당된 가상 코어
애플리케이션 시도 첫 번째 컨테이너 할당 지연 평균 시간
응용 프로그램이 첫 번째 컨테이너 할당 지연 번호를 시도합니다
응용 프로그램이 완료되었습니다
응용 프로그램이 실패했습니다
응용 프로그램이 중지되었습니다
신청 보류 중
실행 중인 애플리케이션
신청서가 제출되었습니다
사용 가능한 메모리
사용 가능한 가상 코어
컨테이너 보류 중
메모리 보류 중
가상 코어 보류 중
컨테이너가 예약되었습니다
메모리가 예약되었습니다
가상 코어 예약됨
사용된 메모리 ApplicationMaster
사용된 가상 코어 ApplicationMaster
사용된 용량입니다
GC 카운트
GC 사본 수
GC 마크 스위프 컴팩트 카운트
GC 번호 정보 임계값을 초과했습니다
GC 번호 경고 임계값을 초과했습니다
GC 시간
GC 복사 시간
GC Marks Sweep Compact Time
GC 총 추가 수면 시간
로그 오류 수
로그 치명적 개수
로그 정보 개수
로그 경고 수
메모리 힙 커밋됨
메모리 힙 최대
메모리 힙 사용
최대 메모리
메모리가 비힙 커밋되었습니다
메모리 비힙 최대
메모리 비힙 사용
스레드가 차단되었습니다
새 스레드
스레드 실행 가능
스레드가 종료되었습니다
스레드 시간 대기 중
스레드가 대기 중입니다 


| Hadoop DataNode를 참조하십시오 | 클러스터
네임스페이스
서버 | 노드 이름
노드 IP
클러스터 ID입니다
버전 | 트랜시버 카운트
전송 진행 중
캐시 용량
사용된 캐시입니다
용량
DFS가 사용되었습니다
예상 손실 용량 합계
마지막 볼륨 실패율입니다
블록 수 캐시됨
블록 수 캐시에 실패했습니다
블록 수를 캐시하지 못했습니다
볼륨 번호가 실패했습니다
남은 용량
GC 카운트
GC 사본 수
GC 마크 스위프 컴팩트 카운트
GC 번호 정보 임계값을 초과했습니다
GC 번호 경고 임계값을 초과했습니다
GC 시간
GC 복사 시간
GC Marks Sweep Compact Time
GC 총 추가 수면 시간
로그 오류 수
로그 치명적 개수
로그 정보 개수
로그 경고 수
메모리 힙 커밋됨
메모리 힙 최대
메모리 힙 사용
최대 메모리
메모리가 비힙 커밋되었습니다
메모리 비힙 최대
메모리 비힙 사용
스레드가 차단되었습니다
새 스레드
스레드 실행 가능
스레드가 종료되었습니다
스레드 시간 대기 중
스레드가 대기 중입니다 


| Hadoop NameNode입니다 | 클러스터
네임스페이스
서버 | 노드 이름
노드 IP
마지막으로 기록된 트랜잭션 ID입니다
마지막으로 로드된 편집 이후의 시간
HA 상태입니다
파일 시스템 상태입니다
블록 풀 ID입니다
클러스터 ID입니다
컴파일 정보
고유 버전 개수
버전 | 블록 용량
총 블록 수
총 용량
사용된 용량입니다
사용된 용량은 비 DFS입니다
블록이 손상되었습니다
예상 손실 용량 합계
블록 초과
하트비트가 만료되었습니다
총 파일 수
파일 시스템 잠금 대기열 길이입니다
블록 없음
요소 1의 복제 누락 블록
클라이언트가 활성 상태입니다
데이터 노드가 작동하지 않음
데이터 노드 사용 중단
데이터 노드 서비스 해제 실시간
데이터 노드 압축 해제
암호화 영역 번호
유지 관리를 시작하는 데이터 노드
작성 중인 파일
유지 보수 시 데이터 노드가 작동하지 않습니다
데이터 노드가 유지 관리 시 라이브 상태로 제공됩니다
데이터 노드 라이브
저장소가 오래되었습니다
복제 보류 시간 초과입니다
데이터 노드 메시지가 보류 중입니다
삭제 보류 중인 블록
복제 보류 중인 블록
블록 복제 오류 연기
블록 예약된 복제
스냅샷 수
Snapshottable 디렉토리
데이터 노드가 잘못되었습니다
총 파일 수
총 하중
총 동기화 수입니다
마지막 체크포인트 이후의 트랜잭션
마지막 로그 롤 이후의 트랜잭션
블록 미복제
볼륨 오류 총계
총 동기화 시간
개체 최대
작업 블록 추가
작업을 통해 스냅샷을 허용합니다
작업 블록이 배치되었습니다
작업 블록 대기 중
작업 차단을 수신하여 삭제했습니다
작업 보고서 평균 시간
작업 블록 보고서 번호
캐시 보고서 평균 시간
캐시 보고서 번호
작업 파일 생성
작업을 통해 스냅샷을 생성합니다
operations symlink를 생성합니다
작업 파일 삭제
작업 스냅샷을 삭제합니다
스냅샷을 허용하지 않는 작업입니다
작업 파일 인/아웃
추가된 파일
파일이 생성되었습니다
파일이 삭제되었습니다
파일 목록
파일 이름이 변경되었습니다
파일이 잘렸습니다
파일 시스템 로드 시간입니다
작업은 EDEK 평균 시간을 생성합니다
EDEK를 생성합니다
작업 시 추가 데이터 노드를 얻습니다
블록 위치 가져오기
편집 평균 시간 보기
편집 번호 가져오기
이미지 가져오기 평균 시간
이미지 번호 가져오기
링크 대상을 가져오는 작업입니다
작업 목록 가져오기
작업 목록 스냅샷 테이블 방향
복제 예약되지 않은 번호입니다
영상 배치 평균 시간
이미지 번호를 넣습니다
스냅샷 이름 바꾸기 작업
리소스 확인 시간 평균 시간
자원 확인 시간 번호
안전 모드 시간
작업 스냅샷 차이 보고서
운영 스토리지 블록 보고서
복제가 완료되었습니다
동기화 평균 시간
작업 동기화 번호
복제 시간 초과
작업 합계
트랜잭션 평균 시간
동기화 상태의 트랜잭션 Batchd
거래 번호
EDEK 예열 시간 평균
EDEK 예열 번호
블록 풀 사용된 공간
캐시 용량
사용된 캐시입니다
사용 가능한 용량
블록 풀 사용 비율입니다
퍼센트 남음
백분율 사용
나사산
GC 카운트
GC 사본 수
GC 마크 스위프 컴팩트 카운트
GC 번호 정보 임계값을 초과했습니다
GC 번호 경고 임계값을 초과했습니다
GC 시간
GC 복사 시간
GC Marks Sweep Compact Time
GC 총 추가 수면 시간
로그 오류 수
로그 치명적 개수
로그 정보 개수
로그 경고 수
메모리 힙 커밋됨
메모리 힙 최대
메모리 힙 사용
최대 메모리
메모리가 비힙 커밋되었습니다
메모리 비힙 최대
메모리 비힙 사용
스레드가 차단되었습니다
새 스레드
스레드 실행 가능
스레드가 종료되었습니다
스레드 시간 대기 중
스레드가 대기 중입니다 


| Hadoop JobHistoryServer를 참조하십시오 | 클러스터
네임스페이스
서버 | 노드 이름
노드 IP | GC 카운트
GC 사본 수
GC 마크 스위프 컴팩트 카운트
GC 번호 정보 임계값을 초과했습니다
GC 번호 경고 임계값을 초과했습니다
GC 시간
GC 복사 시간
GC Marks Sweep Compact Time
GC 총 추가 수면 시간
로그 오류 수
로그 치명적 개수
로그 정보 개수
로그 경고 수
메모리 힙 커밋됨
메모리 힙 최대
메모리 힙 사용
최대 메모리
메모리가 비힙 커밋되었습니다
메모리 비힙 최대
메모리 비힙 사용
스레드가 차단되었습니다
새 스레드
스레드 실행 가능
스레드가 종료되었습니다
스레드 시간 대기 중
스레드가 대기 중입니다 
|===


== 문제 해결

추가 정보는 에서 찾을 수 있습니다 link:concept_requesting_support.html["지원"] 페이지.
